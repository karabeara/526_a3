<head>
  <title>COS 526 Assignment 3 Writeup</title>
  <style type="text/css">
  @font-face {
    font-family: SEATTLE;
    src: url("SEATTLE-Regular.ttf") format("truetype"); 
  }
  body {
  	font-family: SEATTLE, Times, serif;
    color: black;
    background-color: rgb(230,230,230) }
    a 	{ color: #677a93;
    	  text-decoration: none }
    h1	{ font-size: 60px; 
    	  margin-bottom:10px;}
    body, html {
		margin-left:2%;
		margin-right:2%;
		margin-bottom:1%;
		margin-top:0.5%; }
  </style>

  <!-- <link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css"> -->
</head>

<body>
    <script src="js/writeup.js"> </script>
    <div class="main_div">

        <h1 style="font-size: 80px;">PHOTON MAPPING</h1>
        <h2>COS 526, Fall 2018<div>Assignment 3</div></h2>
        <h2>Kara Bressler, karab</h2>

Here, we implement photon mapping, an algorithm for synthesis of global illumination to mimic unbiased lighting.

<br><br>To run this program, run 'make' inside the 'cos526_photon' folder. Then, run the program in the appropriate directory from the command line with the second and third arguments dictating the input scene and the output image names, respectively. Change the number of photons in the global photon map with the '-globalPhotonCount' parameter and the number of photons in the caustic photon map with '-causticPhotonCount' parameter. Resolution can be altered with the '-resolution' parameter.

<br><br><div style='margin-left: 70px;'>./src/photonmap ./input/cornell.scn ./output/cornell_newImage.jpg -resolution 200 200 -globalPhotonCount 4000 -causticPhotonCount 10000</div>

<br>Below, we'll look specifically at the two passes of photon mapping: photon tracing & rendering.

 <br>

</ul></div>

<h1>PHOTON TRACING</h1>

<p><hr><p><a name='Photon Emission'></a><h2>PHOTON EMISSION</h2><p><hr><p>

For every light source in the scene, we emit packets of light which we call photons. The total number of photons emitted from each light source are proportional to the power of the light source such that each photon carries approximately equal power. The assigned R3Light sources all are given the same value for Intensity, and thus we use the respective RNRgb value of the light to determine a light's intensity instead. In order to initially launch each photon into the scene, we created a RandomlySampledRay() function to provide a randomly sample ray from the corresponding light source.

<br><br>

<a href='Results/point_light.png'><img src='Results/point_light.png' width=48%;></a>

<br><br>We implemented the point light by emitting photons from uniformly randomly sampled rays from position of the light source. The spot light serves as a type of point light where beyond a certain angle, the spot light will not emit light. We calculated whether light would be emitted in the uniformly randomly sampled direction by measuring the cosine between the central direction of the spot light and the sampled direction, recalculating the ray if the ray was out of the emitting bounds of the spot light.

<br><br>For the area light, we uniformly choose a spot on the area of the light source and emit a photons along a uniformly randomly sampled rays in the hemisphere as determined by the direction of the light.

<br><br>The directional light is a little different because we are only given the direction of the light. Therefore we rendered an overly-large circle offscreen tilted at the angle of the direction of light and then emitted photons from uniformly randomly sampled rays from the light surface. 

All light intensities follow proper fall-off properties. 
<!-- Here we see 400 photons in a global photon map as calculated 

<br>
<br>

<a href='Results/point_light.png'><img src='Results/point.png' width=24%;></a>
<a href='Results/point_light.png'><img src='Results/spot.png' width=24%;></a>
<a href='Results/point_light.png'><img src='Results/area.png' width=24%;></a>
<a href='Results/point_light.png'><img src='Results/directional.png' width=24%;></a>
 -->
<br>
<br>




<p><hr><p><a name='Photon Scattering'></a><h2>PHOTON SCATTERING</h2><p><hr><p>

During photon scattering, we trace photons via reflected and refracted rays through the scene. At each ray-surface intersection, we generate a secondary ray along a direction of diffuse reflection, specular reflection, transmission or absorption with probability proportional to kd, ks, kt, and (1 - kd+ks+kt) as calculated via BRDF importance sampling analysis.

<br><br> In BRDF importance sampling, we compute the reflected directions of diffuse and specular reflected rays according to the equations from <a href='http://www.cs.princeton.edu/courses/archive/fall18/cos526/papers/importance.pdf'>Jason Lawrence's paper</a>. The specularly reflected ray distribution is centered around the perfect specular reflective direction, and the diffusely reflected ray distribution is centered around the surface normal at the point of ray-surface intersection. Functions for BRDF importance sampling can be found in render.cpp.

<br><br> For each surface intersection during photon tracing, we use Russian Roulette to terminate rays with probabilty p (as determined by the property of the material) and multiply the power of the surviving rays by (1.0 / p). This allows for photons in the scene to have relatively similar powers while following the law of conservation of energy and not introducing more power than was originally emitted into the scene by the original light sources.
<br>
<br>


<p><hr><p><a name='Photon Storage'></a><h2>PHOTON STORAGE</h2><p><hr><p>

Photon-surface intersections are stored in a kd-tree. For each photon we retain the position, incident ray/direction, and power in the following data structure: 

<div style='margin-left: 40px;'>struct Photon {</div>
<!-- <div style='margin-left: 40px;'>{</div> -->
<div style='margin-left: 70px;'>R3Point position;</div>
<div style='margin-left: 70px;'>R3Ray direction;</div>
<div style='margin-left: 70px;'>RNRgb power;</div>
<div style='margin-left: 40px;'>};</div>

<br>
We use the R3Kdtree class in R3Shapes to implement our kd-tree. This provides a fast look-up for the N closest photons in the photon map by using R3Kdtree's FindClosest() method. See Section 2.1.3 in <a href='http://www.cs.princeton.edu/courses/archive/fall18/cos526/papers/jensen01.pdf'>Jensen, 2001</a> for more details about photon storage. 

<br>
<br>


<p><hr><p><a name='Multiple Photon Maps'></a><h2>MULTIPLE PHOTON MAPS</h2><p><hr><p>

We implement two separate photons maps for global (L{S|D}*D) and caustic (LS+D) ray paths. Global ray paths represent the traveling course of all photons emitted from the light sources, while caustic ray paths represent high energy photons from specular and transparent surfaces. Both photon maps are consulted independently at rendering time as we will look at next. Here's a visualization of the placement of photons in the global and caustic photon maps respectively.

<br>
<br>

<a href='Results/global_photons.png'><img src='Results/global_photons.png' width=24%;></a>
<a href='Results/caustic_photons.png'><img src='Results/caustic_photons.png' width=24%;></a>


<br>
<br>


<h1>RENDERING</h1>

<p><hr><p><a name='Camera Raytracing'></a><h2>CAMERA RAYTRACING</h2><p><hr><p>

We implemented a raytracer to deal with transmission of direct light. This raytracing shoots a ray (or multiple rays) from the camera's eye through each pixel and bounces this ray around the scene until a diffuse surface is reached. From this diffuse surface, we then identify the resulting color by adding up contributions from direct ray-traced illumination, indirect illumination from the global photon map, and caustic illumination from the caustic photon map.

<br>
<br>

<p><hr><p><a name='Radiance Estimation'></a><h2>RADIANCE ESTIMATION</h2><p><hr><p>

From a look-up in the global and caustic pre-computed photon maps, radiance is calculated by summing up the N closest photons in the photon map, multiplying by the surface's BRDF, and dividing by the surface area from which the photons were sampled. This is an estimate of surface radiance as we are sampling the light from approximately flat surfaces. Below we see radiance estimations from a global photon map with N=5, N=50, and N=500, from left to right. All images below were rendered from a map of 40,000 global photons.

<br>
<br>

<a href='Results/fog_caustic_indirect_illumination_contribution_5photons.jpg'><img src='Results/fog_caustic_indirect_illumination_contribution_5photons.jpg' width=32%;></a>
<a href='Results/fog_caustic_indirect_illumination_contribution_50photons.jpg'><img src='Results/fog_caustic_indirect_illumination_contribution_50photons.jpg' width=32%;></a>
<a href='Results/fog_caustic_indirect_illumination_contribution_500photons.jpg'><img src='Results/fog_caustic_indirect_illumination_contribution_500photons.jpg' width=32%;></a>

<br>
<br>

As for volume and volume caustic pre-computed photon maps, radiance is calculated by summing up the N closest photons in the respective photon map, multiplying by the phase function (we sample uniformly in all directions so this is inconsequential for us), and dividing by the volume from which the photons were sampled. This is an estimate of volumetric radiance as we are sampling light's interaction with the participating medium and thus the photon interactions are occuring in 3D space. 

<br>
<br>

We implemented cone and Gaussian filtering methods for weighting photons during radiance estimation. We did not observe a large difference in radiance estimates with or without filtering. See the EstimateSurfaceRadiance() function in render.cpp for implementation.

<br>
<br>


<p><hr><p><a name='Pixel integration'></a><h2>PIXEL INTEGRATION</h2><p><hr><p>

For antialiasing, we provide the ability send multiple rays out per pixel. Instead of shooting rays out directly from the rays

For surfaces with a combination of diffuse, specular, transparent, and absorbing properties, we want to trace multiple rays per pixel (N) and average the radiance computed for all rays to estimate the radiance to store in the output image for each pixel. 

<br><br>Below from left to right, we see an example with N=1, N=4, N=16, and N=32. 

<br>
<br>

<a href='Results/stack_004_1_ray_per_pixel_HUGE.jpg'><img src='Results/stack_004_1_ray_per_pixel.jpg' width=24%;></a>
<a href='Results/stack_004_4_rays_per_pixel.jpg'><img src='Results/stack_004_4_rays_per_pixel.jpg' width=24%;></a>
<a href='Results/stack_004_16_rays_per_pixel.jpg'><img src='Results/stack_004_16_rays_per_pixel.jpg' width=24%;></a>
<a href='Results/stack_004_32_rays_per_pixel_HUGE.jpg'><img src='Results/stack_004_32_rays_per_pixel.jpg' width=24%;></a>


<br><br><br>And here we see an example with the raytraced version on the left and our rendition with N=32 on the right.

<br>
<br>

<a href='Results/stilllife004_raytracer.jpg'><img src='Results/stilllife004_raytracer.jpg' width=24%;></a>
<a href='Results/stilllife004_32_rays_per_pixel_40000global_10000caustic.jpg'><img src='Results/stilllife004_32_rays_per_pixel_40000global_10000caustic.jpg' width=24%;></a>


<br>
<br>


<p><hr><p><a name='Participating Medium'></a><h2>PARTICIPATING MEDIUM</h2><p><hr><p>

We conducted ray-marching in the scene to calculate single scattering. For every ray shot into the scene, we would sample N uniformly distributed points on the ray's trajectory. For each light source, if there exists a direct path from the sampled point to the corresponding light, a medium- and light-specific contribution is added to the corresponsing ray radiance estimation. Here's an example where we sample N=100 samples per ray for 6 separate renders.

<br> 
<br>

<a href='Results/participating_medium.gif'><img src='Results/participating_medium.gif'></a>

<br>
<br>

In the future we could run the program with two extra photon maps: a volume photon map & a volume caustics photon map. While ray-marching along these N uniformly distributed points on the ray of camera -> surface-intersection, we would look up in our new respective maps the closest N photons to each of the sampled points along the march, then calculating the contribution from the volumetric radiance estimation.



<h1>ART GALLERY</h1>


<p><hr><p>

Below we see the contributions of raytracing for direct illumination, global photon map look-up for indirect illumination, caustic photon map look-up for caustics, and ray marching for the participating medium, from left to right respectively.

<br> <br>

<a href='Results/fog_caustic_raytracer_contribution.jpg'><img src='Results/fog_caustic_raytracer_contribution.jpg' width=24%;></a>
<a href='Results/fog_caustic_indirect_illumination_contribution.jpg'><img src='Results/fog_caustic_indirect_illumination_contribution.jpg' width=24%;></a>
<a href='Results/fog_caustic_caustic_contribution.jpg'><img src='Results/fog_caustic_caustic_contribution.jpg' width=24%;></a>
<a href='Results/fog_caustic_medium_contribution.jpg'><img src='Results/fog_caustic_medium_contribution.jpg' width=24%;></a>

<br><br>

The sum of the above contributions create the following result: 

<br><br>

<a href='Results/fog_caustic_full.jpg'><img src='Results/fog_caustic_full.jpg' width=33%;></a>

<br>
<br>

With more time we would implement volume caustics and further integrate the participating medium.

<br>
<br>


<p><hr><p><a name='Mistakes'></a><h2>MISTAKES</h2><p><hr><p>

For your viewing pleasure, here is a compilation of all saved renders in the process of creating the photon mapping. We used the Cornell Box as the basis for testing for most of this project.

<br>
<br>

<a href='Results/photon_mapping_mistakes.gif'><img src='Results/photon_mapping_mistakes.gif' width=100px;></a>


<br>
<br>

Here's also an attempt at rendering the specular ring we've seen all the time in class. This is just the caustic rendering without direct / indirection illumination.


<br>
<br>

<a href='Results/ring_caustics.jpg'><img src='Results/ring_caustics.jpg' width=24%;></a>


<br>
<br>








<br>
<br>
<br>
<br>





<a name='Resources'></a><h2>RESOURCES</h2><p><hr><p>
Here's a list of the resources consulted and used to complete this photon mapping assignment:

<ul>

<li> 
	<a href='http://www.cs.princeton.edu/courses/archive/fall18/cos526/papers/jensen01.pdf'>A Practical Guide to Global Illumination using Photon Mapping</a>, Henrik Wann Jensen, 2001.</li>
</li>
<li>
	<a href='http://www.cs.princeton.edu/courses/archive/fall18/cos526/notes/cos526_f18_lecture17_photon.pdf'>CSE272: Advanced Image Synthesis lecture notes shown in COS 526</a>, Henrik Wann Jensen, 2010.</li>
</li>
<li>
	<a href='http://www.cs.princeton.edu/courses/archive/fall18/cos526/papers/importance.pdf'>Importance Sampling of the Phong Reflectance Model</a>, Jason Lawrence.</li>
</li>
<li>
	<a href='http://www.cs.princeton.edu/courses/archive/fall18/cos526/assignment3.html'>Previous COS 526 Student Write-ups</a>, 2012-2014.</li>
</li>
<li>
	<a href='http://www.cs.princeton.edu/courses/archive/fall18/cos526/a3/cos526_photon.zip'>C++ template code</a>, courtesy of Tom Funkhouser.</li>
</li>
<li>
  <a href='https://cs.dartmouth.edu/wjarosz/publications/dissertation/chapter7.pdf'>The Photon Mapping Method</a>, Wojciech Jarosz on Volume Photon Mapping.</li>
</li>




</ul>

<br>
This write-up is written in the SEATTLE typeface as part of my <a href='https://karabeara.github.io/portfolio/pages/topo-typo.html'>Topography Typography project</a>.



<br>
<br>
<br>





<br>
  </div>
</body>
</html>
